\chapter*{Conclusion}  % chapter* je necislovana kapitola
\addcontentsline{toc}{chapter}{Conclusion} % rucne pridanie do obsahu
\markboth{Conclusion}{Conclusion} % vyriesenie hlaviciek

We have designed, developed and tested a novel algorithm for DNA barcode demultiplexing that works in an unsupervised manner in the raw signal space. To the best of our knowledge, we are the first to have addressed the problem in this way, not requiring the information about the inner structure of barcode sequences. Thus, our solution can be applied to any barcoding kit without the need of retraining the model. Moreover, the decisions of the presented model are interpretable as opposed to the neural network based models.

During our research, we have identified several drawbacks of the Native Barcoding Kit developed by ONT \cite{BarcodesONT}. The most significant issue is that not all pairs of barcodes are equally dissimilar in the signal space, which then takes its toll in demultiplexing, where we have observed a tendency of a barcode $1$ appearing as a very similar to the barcode $4$. This renders some pairs of the barcodes unsuitable to use simultaneously.

\section*{Future work}
In the end, we present some ideas for future research and enhancements of this algorithm.

\subsection*{Improving Computation Time}
We have identified some directions for the overall speed up of our algorithm. The most drastic speed up would be probably brought by employing a computing on a graphics processing unit (GPU). Modern GPUs usually have lower processor frequency, but possess a larger number of cores/threads by several orders of magnitude. Since the computation of LDTW scores on matrices is a trivially parallelizable problem, we could well benefit from the level of parallelism GPUs offer. CUDA framework \cite{CUDA} for NVIDIA GPUs seems to be a reasonable choice for implementation.

Faster computation of LDTW scores would allow for a computation of larger discovery matrices and consequently a more extensive search for suitable representatives. In the clustering phase, this would also allow a to use a larger number of representatives from each cluster. We note that the robustness of our algorithm may be heavily influenced by the number of representatives used and for that reason the algorithm may have a smooth trade-off curve between the computation time and demultiplexing accuracy. Thus, we could potentially increase the precision and/or recall even further by increasing the computational power.

Additionally, the speed up would allow to use a larger number of barcodes in experiments, without experiencing the drawbacks caused by a poor representation of a barcode in the discovery sample due to the small sample size.

\subsection*{Improving classification accuracy}
To follow up our examination of the many parameters our algorithm offers, it is needed to say that we only explored a small fraction of the whole parameter space. Exploring the influences of the parameters further may provide fruitful.

Other than a more extensive exploration of parameters, we propose the following ideas for further improvements of the algorithm:

\begin{itemize}
    \item Train a $2$D scoring scheme, i.e. a scoring scheme that is dependent on the values of both of the squiggle points instead of their distance
    \item Explore be the usage of the length of a LDTW alignment path as a similarity metric instead of its score or the joint usage of both
    \item Explore the solutions for class imbalancedness in either spectral clustering (e.g. Qian et al. \cite{qian2013spectral}) or in general
\end{itemize}


\subsubsection*{Independence of events}
In this thesis we worked under an assumption that the sequence points are independent events in the probability space. We adopted this model from Durbin et al. \cite{Durbin1998}. While it may be a reasonable assumption for more discrete sequences like DNA nucleotides, in our setting we are working with raw signal values and each base flowing through the nanopore can generate as many as tens of measurements. Additionally, the transitions between current levels generated by flowing nucleobases are smooth, which disrupts our assumption. We might be interested in taking into account several values from the history, possibly with a decreasing weight towards the older ones. We could therefore train a scoring scheme that would be in the following form:

\begin{multline}
    s(X, Y) = \sum_{i=1}^n s(x_i, y_i) = \\
      = \sum_{t=1}^n \frac{P(x_t, y_t ~|~ x_{t-1} = a_{t_1},\cdots,x_{t-k} = a_{t_k}; y_{t-1} = b_{t_1},\cdots,y_{t-k} = b_{t_k})}{P(x_t ~|~ x_{t-1} = a_{t_1},\cdots,x_{t-k})P(y_t ~|~ y_{t-1} = b_{t_1},\cdots,y_{t-k})} =\\
      = P(H ~|~ X, Y)
\end{multline}

We may also inquire about whether we can construct the simulated barcode squiggles from a sample of squiggles, without the prior knowledge about the structure of the barcodes.
